{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLX Server Structured Output Examples\n",
    "\n",
    "This is a detailed text version of the structured output examples for MLX Server with OpenAI-compatible API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the client\n",
    "\n",
    "Connect to your local MLX server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url = \"http://localhost:8000/v1\",\n",
    "    api_key = \"mlx-server-api-key\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function calling example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user message\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the weather in Tokyo?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define the available tools/functions\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get the weather in a given city\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\"type\": \"string\", \"description\": \"The city to get the weather for\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Streaming Function Calling Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl_1767021264227320', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_1767021264722063', function=Function(arguments='{\"city\": \"Tokyo\"}', name='get_weather'), type='function', index=0)], reasoning_content='Okay, the user is asking about the weather in Tokyo. Let me check the tools available. There\\'s a function called get_weather that takes a city name as a parameter. The user specified Tokyo, so I need to call this function with city set to \"Tokyo\". I\\'ll make sure to format the tool call correctly in JSON inside the tool_call tags.\\n', tool_call_id=None))], created=1767021264, model='mlx-server-model', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=96, prompt_tokens=162, total_tokens=258, completion_tokens_details=None, prompt_tokens_details=None), request_id=None)\n"
     ]
    }
   ],
   "source": [
    "# Make the API call\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"mlx-server-model\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    max_tokens = 512\n",
    ")\n",
    "\n",
    "# Get the result\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Function Calling Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=None), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content='Okay,'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' the'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' user'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' is'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' asking'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' about'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' the'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' weather'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' in'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' Tokyo.'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' Let'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' me'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' check'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' the'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' tools'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' provided.'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=\" There's\"), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' a'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' function'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' called'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' get_weather'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' that'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' takes'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' a'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' city'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' name'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' as'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' a'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' parameter.'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' The'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' user'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' specified'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' Tokyo,'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' so'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' I'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' need'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' to'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' call'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' that'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' function'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' with'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' the'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' city'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' set'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' to'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' Tokyo.'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=\" I'll\"), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' make'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' sure'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' to'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' format'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' the'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' tool'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' call'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' correctly'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' in'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' JSON'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' within'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' the'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' specified'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=''), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None, reasoning_content=' tags.\\n'), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=0, id='call_1767020971010696', function=ChoiceDeltaToolCallFunction(arguments='{\"city\": \"Tokyo\"}', name='get_weather'), type='function')], reasoning_content=None), finish_reason=None, index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, request_id=None)\n",
      "ChatCompletionChunk(id='chatcmpl_1767020969915584', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None, reasoning_content=None), finish_reason='tool_calls', index=0, logprobs=None)], created=1767020969, model='mlx-server-model', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=94, prompt_tokens=162, total_tokens=256, completion_tokens_details=None, prompt_tokens_details=None), request_id=None)\n"
     ]
    }
   ],
   "source": [
    "# Set stream=True in the API call\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"mlx-server-model\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "# Process the streaming response\n",
    "for chunk in completion:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Schema Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Extract the address from the user input into the specified JSON format.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Please format this address: 1 Hacker Wy Menlo Park CA 94025\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response_format = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"Address\",\n",
    "        \"schema\": {\n",
    "            \"properties\": {\n",
    "                \"address\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"street\": {\"type\": \"string\"},\n",
    "                    \"city\": {\"type\": \"string\"},\n",
    "                    \"state\": {\n",
    "                    \"type\": \"string\", \n",
    "                    \"description\": \"2 letter abbreviation of the state\"\n",
    "                    },\n",
    "                    \"zip\": {\n",
    "                    \"type\": \"string\", \n",
    "                    \"description\": \"5 digit zip code\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"street\", \"city\", \"state\", \"zip\"]\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"address\"],\n",
    "            \"type\": \"object\"\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-streaming Structured Output Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl_1754135313793796', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"address\": {\"street\": \"1 Hacker Wy\", \"city\": \"Menlo Park\", \"state\": \"CA\", \"zip\": \"94025\"}}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning_content=None))], created=1754135313, model='mlx-server-model', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None)\n"
     ]
    }
   ],
   "source": [
    "# Make the API call\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"mlx-server-model\",\n",
    "    messages=messages,\n",
    "    max_tokens = 512,\n",
    "    response_format = response_format\n",
    ")\n",
    "\n",
    "# Get the result\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Structured Output Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"address\": {\"street\": \"1 Hacker Wy\", \"city\": \"Menlo Park\", \"state\": \"CA\", \"zip\": \"94025\"}}"
     ]
    }
   ],
   "source": [
    "# Make the API call\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"mlx-server-model\",\n",
    "    messages=messages,\n",
    "    max_tokens = 512,\n",
    "    response_format = response_format,\n",
    "    stream = True\n",
    ")\n",
    "\n",
    "# Process the streaming response\n",
    "for chunk in completion:\n",
    "    if chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
